{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potato Disease Classification\n",
    "\n",
    "*This notebook demonstrates a complete machine learning pipeline for classifying potato plant diseases using deep learning with TensorFlow.*\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "Potato diseases can cause significant crop loss for farmers worldwide. Early detection of these diseases is crucial for effective treatment and prevention of crop damage. This project uses Convolutional Neural Networks (CNNs) to classify potato leaves into three categories:\n",
    "\n",
    "1. Early Blight (Alternaria solani)\n",
    "2. Late Blight (Phytophthora infestans)\n",
    "3. Healthy\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Setup and Dependencies](#setup-and-dependencies)\n",
    "2. [Data Acquisition and Preparation](#data-acquisition-and-preparation)\n",
    "3. [Data Exploration and Visualization](#data-exploration-and-visualization)\n",
    "4. [Data Preprocessing](#data-preprocessing)\n",
    "5. [Model Building and Training](#model-building-and-training)\n",
    "6. [Model Evaluation](#model-evaluation)\n",
    "7. [Deployment](#deployment)\n",
    "\n",
    "## Setup and Dependencies\n",
    "\n",
    "*First, we'll import all the necessary libraries for our project.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep learning framework\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    MaxPool2D,\n",
    "    RandomFlip,\n",
    "    RandomRotation,\n",
    "    RandomZoom,\n",
    "    Rescaling,\n",
    "    Resizing,\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Machine learning evaluation metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Image processing\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Utilities\n",
    "from tqdm import tqdm\n",
    "import gradio as gr\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition and Preparation\n",
    "\n",
    "### Downloading Dataset from Kaggle\n",
    "\n",
    "*We'll use the PlantVillage dataset from Kaggle, which contains images of various plant diseases including potato diseases.*\n",
    "\n",
    "**Note:** To download from Kaggle, you need to:\n",
    "1. Create a Kaggle account if you don't have one\n",
    "2. Go to your account settings and create an API token\n",
    "3. Download the kaggle.json file and upload it below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading on Google Colab\n",
    "Run the next cell if you are using Google Colab otherwise refer the next cell if you are running it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Kaggle API and setup authentication\n",
    "%pip install -q kaggle\n",
    "from google.colab import files\n",
    "\n",
    "# Upload your kaggle.json API token file (skip if already uploaded)\n",
    "files.upload()\n",
    "\n",
    "# Create a Kaggle directory and set permissions for the API token\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# Download the PlantVillage dataset\n",
    "!kaggle datasets download -d arjuntejaswi/plant-village\n",
    "\n",
    "# Extract the downloaded dataset\n",
    "!unzip plant-village.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading locally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"DATASET\", exist_ok=True)\n",
    "\n",
    "kaggle_json_path = os.path.expanduser(\"kaggle.json\")\n",
    "kaggle_dir = os.path.expanduser(\"~/.kaggle\")\n",
    "os.makedirs(kaggle_dir, exist_ok=True)\n",
    "if not os.path.exists(os.path.join(kaggle_dir, \"kaggle.json\")):\n",
    "    shutil.copy(kaggle_json_path, os.path.join(kaggle_dir, \"kaggle.json\"))\n",
    "\n",
    "os.chmod(os.path.join(kaggle_dir, \"kaggle.json\"), 0o600)\n",
    "\n",
    "!kaggle datasets download -d arjuntejaswi/plant-village -p \"DATASET\"\n",
    "\n",
    "with zipfile.ZipFile(\"DATASET/plant-village.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"DATASET\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Potato Disease Images\n",
    "\n",
    "*The PlantVillage dataset contains images of various plants and diseases. For this project, we'll focus only on potato diseases, so we'll extract just those images.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define source and destination directories\n",
    "data_dir = \"/content/PlantVillage\"  # Original dataset location\n",
    "save_dir = \"PotatoDir\"  # Where we'll save potato images\n",
    "\n",
    "# Create a new directory structure with only potato-related folders\n",
    "for folder in tqdm(os.listdir(data_dir), desc=\"Extracting potato images\"):\n",
    "    # Select only folders that contain potato images\n",
    "    if folder.startswith(\"Potato\"):\n",
    "        folder_path = os.path.join(save_dir, folder)\n",
    "\n",
    "        # Ensure the destination folder exists\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "        # Add a short delay to ensure the filesystem catches up\n",
    "        # This helps prevent file not found errors\n",
    "        import time\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Copy all images from the source to the destination folder\n",
    "        for image_file in os.listdir(os.path.join(data_dir, folder)):\n",
    "            src = os.path.join(data_dir, folder, image_file)\n",
    "            dst = os.path.join(folder_path, image_file)\n",
    "            try:\n",
    "                shutil.copy(src, dst)\n",
    "            except FileNotFoundError as e:\n",
    "                print(f\"File not found: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the extraction by counting images in each class\n",
    "print(\"Class distribution in the potato disease dataset:\")\n",
    "for folder in os.listdir(save_dir):\n",
    "    image_count = len(os.listdir(os.path.join(save_dir, folder)))\n",
    "    print(f\"{folder} : {image_count} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration and Visualization\n",
    "\n",
    "### Loading the Dataset\n",
    "\n",
    "*Now we'll load our potato disease images using TensorFlow's dataset utilities, which will help us efficiently process and batch the data for training.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image processing parameters\n",
    "IMAGE_SIZE = 256  # All images will be resized to 256x256 pixels\n",
    "BATCH_SIZE = 32  # Number of images processed in each training batch\n",
    "\n",
    "# Load images from the directory with automatic labeling based on the folder structure\n",
    "save_dir = \"/content/PotatoDir\"\n",
    "dataset = image_dataset_from_directory(\n",
    "    save_dir,  # Path to the image directory\n",
    "    shuffle=True,  # Shuffle data to prevent model memorization\n",
    "    image_size=(IMAGE_SIZE, IMAGE_SIZE),  # Resize all images to consistent dimensions\n",
    "    batch_size=BATCH_SIZE,  # Define batch size for training\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract class names from the dataset\n",
    "class_names = dataset.class_names\n",
    "print(\"Classes in our dataset:\")\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"  {i}: {class_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the shape of our batched data\n",
    "print(\"Dataset structure:\")\n",
    "for image_batch, labels_batch in dataset.take(1):\n",
    "    print(f\"Image batch shape: {image_batch.shape}\")\n",
    "    print(f\"Label batch shape: {labels_batch.shape}\")\n",
    "    print(f\"Labels in this batch: {labels_batch.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Sample Images\n",
    "\n",
    "*Let's examine some sample images from each class to better understand our dataset. This will help us identify any potential issues and get familiar with the visual characteristics of each disease.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 14))\n",
    "fig.suptitle(\"Sample Images from the Potato Disease Dataset\", fontsize=20)\n",
    "\n",
    "# Take one batch of images and display the first 16\n",
    "for image_batch, label_batch in dataset.take(1):\n",
    "    for i in range(16):\n",
    "        # Create a subplot in a 4x4 grid\n",
    "        ax = plt.subplot(4, 4, i + 1)\n",
    "\n",
    "        # Convert tensor to a numpy array and display the image\n",
    "        plt.imshow(image_batch[i].numpy().astype(np.uint8))\n",
    "\n",
    "        # Add the class names as the subplot title\n",
    "        class_name = class_names[label_batch.numpy()[i]]\n",
    "        plt.title(class_name.replace(\"Potato___\", \"\").replace(\"_\", \" \"), fontsize=12)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Observations about the Dataset\n",
    "\n",
    "*From the sample images, we can observe:*\n",
    "\n",
    "- **Early Blight**: Characterized by brown spots with concentric rings, typically on older leaves\n",
    "- **Late Blight**: Shows dark brown patches with fuzzy white growth in humid conditions\n",
    "- **Healthy**: Green leaves without visible lesions or discoloration\n",
    "\n",
    "*These visual differences will be important features for our model to learn.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "*Before training our model, we need to prepare our data by splitting it into training, validation, and test sets, and setting up data augmentation to improve model generalization.*\n",
    "\n",
    "### Splitting the Dataset\n",
    "\n",
    "*We'll use a standard 80/10/10 split:*\n",
    "- *80% for training (learning patterns)*\n",
    "- *10% for validation (tuning hyperparameters)*\n",
    "- *10% for testing (final evaluation)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(\n",
    "    ds, train_ratio, val_ratio, test_ratio, shuffle=True, shuffle_size=10000\n",
    "):\n",
    "    \"\"\"\n",
    "    Split a TensorFlow dataset into training, validation, and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    ds : tf.data.Dataset\n",
    "        The dataset to split\n",
    "    train_ratio : float\n",
    "        Proportion of data to use for training (e.g., 0.8 for 80%)\n",
    "    val_ratio : float\n",
    "        Proportion of data to use for validation (e.g., 0.1 for 10%)\n",
    "    test_ratio : float\n",
    "        Proportion of data to use for testing (e.g., 0.1 for 10%)\n",
    "    shuffle : bool\n",
    "        Whether to shuffle the dataset before splitting\n",
    "    shuffle_size : int\n",
    "        Buffer size for shuffling\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    train_ds, val_ds, test_ds : tuple of tf.data.Dataset\n",
    "        The split datasets\n",
    "    \"\"\"\n",
    "    # Shuffle the dataset if requested (with a fixed seed for reproducibility)\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle_size, seed=2024)\n",
    "\n",
    "    # Calculate the size of each split\n",
    "    TRAIN_SIZE = int(len(ds) * train_ratio)\n",
    "    VAL_SIZE = int(len(ds) * val_ratio)\n",
    "    TEST_SIZE = int(len(ds) * test_ratio)\n",
    "\n",
    "    # Split the dataset\n",
    "    train_ds = ds.take(TRAIN_SIZE)\n",
    "    val_ds = ds.skip(TRAIN_SIZE).take(VAL_SIZE)\n",
    "    test_ds = ds.skip(TRAIN_SIZE + VAL_SIZE).take(TEST_SIZE)\n",
    "\n",
    "    # Optimize dataset performance with caching, shuffling and prefetching\n",
    "    train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset using our function with an 80/10/10 ratio\n",
    "train_ds, val_ds, test_ds = split_dataset(dataset, 0.8, 0.1, 0.1)\n",
    "\n",
    "# Verify our split sizes\n",
    "print(\"Dataset split summary:\")\n",
    "print(f\"  Training batches:   {len(train_ds)} ({len(train_ds) * BATCH_SIZE} images)\")\n",
    "print(f\"  Validation batches: {len(val_ds)} ({len(val_ds) * BATCH_SIZE} images)\")\n",
    "print(f\"  Testing batches:    {len(test_ds)} ({len(test_ds) * BATCH_SIZE} images)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing Pipeline\n",
    "\n",
    "*We'll create two preprocessing components:*\n",
    "\n",
    "1. **Resize and Rescale**: Ensures all images have consistent dimensions and pixel values in the range [0,1]\n",
    "2. **Data Augmentation**: Generates new training examples by applying random transformations to existing images\n",
    "\n",
    "#### Resize and Rescale Layer\n",
    "\n",
    "*This preprocessing step standardizes our input images:*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sequential model for resizing and rescaling images\n",
    "resize_rescale = Sequential(\n",
    "    [\n",
    "        # Resize all images to a standard size\n",
    "        Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        # Rescale pixel values from [0,255] to [0,1]\n",
    "        Rescaling(1.0 / 255),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation\n",
    "\n",
    "*Data augmentation is a powerful technique to prevent overfitting and improve model generalization. By creating variations of our training images, we help the model learn more robust features.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sequential model for data augmentation\n",
    "data_augmentation = Sequential(\n",
    "    [\n",
    "        # Randomly flip images both horizontally and vertically\n",
    "        # This simulates different plant orientations\n",
    "        RandomFlip(\"horizontal_and_vertical\"),\n",
    "        # Randomly rotate images by up to 40% in either direction\n",
    "        # This helps the model become invariant to the orientation of leaves\n",
    "        RandomRotation(0.4),\n",
    "        # Randomly zoom in/out by up to 20%\n",
    "        # This simulates variations in distance from the plant\n",
    "        RandomZoom(0.2),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*These augmentation techniques will help our model generalize better to new, unseen images and become more robust to variations in how the potato leaves are photographed.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Data Augmentation Effects\n",
    "\n",
    "*Let's visualize how our augmentation techniques transform the original images. This helps us understand what variations our model will learn from.*\n",
    "\n",
    "#### Random Rotation Visualization\n",
    "\n",
    "*Random rotation simulates different angles at which the leaves might be photographed.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_rotation(ds, factor):\n",
    "    \"\"\"Visualize the effect of random rotation on sample images\"\"\"\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(f\"Effect of Random Rotation (Factor: {factor})\", fontsize=16)\n",
    "\n",
    "    # Create a rotation layer with the specified factor\n",
    "    rand_rot = RandomRotation(factor)\n",
    "\n",
    "    for image, label in ds.take(1):\n",
    "        for i in range(2):\n",
    "            # Original image\n",
    "            axs[i, 0].imshow(image[i].numpy().astype(np.uint8))\n",
    "            class_name = (\n",
    "                class_names[label[i]].replace(\"Potato___\", \"\").replace(\"_\", \" \")\n",
    "            )\n",
    "            axs[i, 0].set_title(f\"Original: {class_name}\", fontsize=12)\n",
    "            axs[i, 0].axis(\"off\")\n",
    "\n",
    "            # Rotated image\n",
    "            rotated_image = rand_rot(image[i]).numpy().astype(np.uint8)\n",
    "            axs[i, 1].imshow(rotated_image)\n",
    "            axs[i, 1].set_title(f\"Rotated: {class_name}\", fontsize=12)\n",
    "            axs[i, 1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Visualize rotation with a factor of 0.5 (up to 180 degrees)\n",
    "visualize_rotation(train_ds, 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Zoom Visualization\n",
    "\n",
    "*Random zoom simulates variations in camera distance and focus when photographing plant leaves.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_zoom(ds, factor):\n",
    "    \"\"\"Visualize the effect of random zoom on sample images\"\"\"\n",
    "    fig, axs = plt.subplots(4, 4, figsize=(14, 14))\n",
    "    fig.suptitle(f\"Effect of Random Zoom (Factor: {factor})\", fontsize=18)\n",
    "\n",
    "    # Create a zoom layer with the specified factor\n",
    "    rand_zoom = RandomZoom(factor)\n",
    "\n",
    "    for image, label in ds.take(1):\n",
    "        for i in range(8):\n",
    "            row, col = i // 2, (i % 2) * 2\n",
    "\n",
    "            # Original image\n",
    "            axs[row, col].imshow(image[i].numpy().astype(np.uint8))\n",
    "            class_name = (\n",
    "                class_names[label[i]].replace(\"Potato___\", \"\").replace(\"_\", \" \")\n",
    "            )\n",
    "            axs[row, col].set_title(f\"Original: {class_name}\", fontsize=10)\n",
    "            axs[row, col].axis(\"off\")\n",
    "\n",
    "            # Zoomed image\n",
    "            zoomed_image = rand_zoom(image[i]).numpy().astype(np.uint8)\n",
    "            axs[row, col + 1].imshow(zoomed_image)\n",
    "            axs[row, col + 1].set_title(f\"Zoomed: {class_name}\", fontsize=10)\n",
    "            axs[row, col + 1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.95)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Visualize zoom with a factor of 0.5 (zoom in/out by up to 50%)\n",
    "visualize_zoom(train_ds, 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*These visualizations show how data augmentation creates diverse training examples from our original dataset. The model will learn to recognize diseases regardless of the leaf orientation, angle, or how zoomed in the photo is.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building and Training\n",
    "\n",
    "*Now we'll design and train a Convolutional Neural Network (CNN) to classify potato diseases.*\n",
    "\n",
    "### CNN Architecture Design\n",
    "\n",
    "*CNNs are the standard architecture for image classification tasks. Our model will use:*\n",
    "\n",
    "- *Multiple convolutional layers to extract features from images*\n",
    "- *Max pooling to reduce dimensionality and computational load*\n",
    "- *Dense layers at the end for classification*\n",
    "- *Data augmentation during training to improve generalization*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine our image parameters\n",
    "IMAGE_SIZE = 256  # Input image dimensions\n",
    "BATCH_SIZE = 32  # Batch size for training\n",
    "\n",
    "# Define the input shape for our model\n",
    "input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)  # Height, Width, Channels\n",
    "\n",
    "# Build a sequential CNN model\n",
    "seq_model = Sequential(\n",
    "    [\n",
    "        # Input layer specifying the input shape\n",
    "        Input(shape=input_shape),\n",
    "        # Preprocessing layers\n",
    "        resize_rescale,  # Resize and normalize images\n",
    "        data_augmentation,  # Apply data augmentation during training\n",
    "        # First convolutional block\n",
    "        Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "        # Second convolutional block (doubling filters)\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "        # Third convolutional block (doubling filters again)\n",
    "        Conv2D(filters=128, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "        # Fourth convolutional block (doubling filters again)\n",
    "        Conv2D(filters=256, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "        # Flatten the 3D feature maps to 1D feature vectors\n",
    "        Flatten(),\n",
    "        # First dense layer for a high-level feature combination\n",
    "        Dense(units=128, activation=\"relu\"),\n",
    "        # Output layer with softmax activation for multi-class classification\n",
    "        # Number of units equals the number of disease classes\n",
    "        Dense(units=len(class_names), activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "seq_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Model Architecture Highlights:*\n",
    "\n",
    "- *Progressive increase in filter count (32→64→128→256) to learn hierarchical features*\n",
    "- *Max pooling after each convolutional layer to reduce spatial dimensions*\n",
    "- *ReLU activation for non-linearity in feature extraction*\n",
    "- *128-unit dense layer to combine high-level features*\n",
    "- *Softmax output to get class probabilities*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Compilation\n",
    "\n",
    "*Before training, we need to compile the model by specifying:*\n",
    "\n",
    "- *Optimizer: Algorithm to update the model weights*\n",
    "- *Loss function: Measures how far the model's predictions are from the true values*\n",
    "- *Metrics: Used to monitor the training and evaluation process*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with appropriate settings for a classification task\n",
    "seq_model.compile(\n",
    "    # Adam optimizer with default learning rate (good for most tasks)\n",
    "    optimizer=\"adam\",\n",
    "    # Sparse categorical crossentropy is appropriate when classes are mutually exclusive\n",
    "    # and labels are integers (not one-hot encoded)\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Callbacks\n",
    "\n",
    "*Callbacks allow us to customize the training process. We'll use:*\n",
    "\n",
    "- *EarlyStopping: Stops training when a monitored metric stops improving*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callback for early stopping\n",
    "cb = EarlyStopping(\n",
    "    monitor=\"val_loss\",  # Monitor validation loss\n",
    "    patience=5,  # Number of epochs with no improvement after which to stop\n",
    "    verbose=1,  # Provides updates in the console\n",
    "    restore_best_weights=True,  # Restore the best weights when stopped\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "*Now we'll train our model on the prepared dataset. The model will learn to identify patterns associated with each disease class.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track the start time to measure training duration\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "history = seq_model.fit(\n",
    "    train_ds,  # Training dataset\n",
    "    epochs=25,  # Maximum number of complete passes through the dataset\n",
    "    batch_size=BATCH_SIZE,  # Number of samples per gradient update\n",
    "    validation_data=val_ds,  # Dataset for validation\n",
    "    callbacks=[cb],  # List of callbacks to apply during training\n",
    "    verbose=1,  # Progress bar mode\n",
    ")\n",
    "\n",
    "# Calculate and print training time\n",
    "training_time = time.time() - start_time\n",
    "print(\n",
    "    f\"\\nTraining completed in {training_time:.2f} seconds ({training_time / 60:.2f} minutes)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*During training, we can observe:*\n",
    "\n",
    "1. *The loss and accuracy on both training and validation sets*\n",
    "2. *Whether the model is improving over epochs*\n",
    "3. *If/when early stopping is triggered*\n",
    "\n",
    "*This gives us insights into how well our model is learning the patterns in the data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Training Results\n",
    "\n",
    "*Let's examine how our model performed during training by visualizing the training history.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the final values in our training history\n",
    "final_epoch = len(history.history[\"loss\"]) - 1\n",
    "print(f\"Training Results after {final_epoch + 1} epochs:\")\n",
    "print(f\"  Training Accuracy:   {history.history['accuracy'][final_epoch]:.4f}\")\n",
    "print(f\"  Validation Accuracy: {history.history['val_accuracy'][final_epoch]:.4f}\")\n",
    "print(f\"  Training Loss:       {history.history['loss'][final_epoch]:.4f}\")\n",
    "print(f\"  Validation Loss:     {history.history['val_loss'][final_epoch]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create an interactive visualization of training history\n",
    "def plot_history(history):\n",
    "    \"\"\"Create an interactive plot of training history using Plotly\"\"\"\n",
    "    # Extract metrics from the history object\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    acc = history.history[\"accuracy\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "\n",
    "    # Find the best epochs for loss and accuracy\n",
    "    best_loss_epoch = np.argmin(val_loss)\n",
    "    best_acc_epoch = np.argmax(val_acc)\n",
    "\n",
    "    # Create subplots for loss and accuracy\n",
    "    fig = make_subplots(\n",
    "        rows=1,\n",
    "        cols=2,\n",
    "        subplot_titles=(\"Model Loss\", \"Model Accuracy\"),\n",
    "        shared_xaxes=True,\n",
    "    )\n",
    "\n",
    "    # Add loss traces\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=list(range(len(loss))),\n",
    "            y=loss,\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"#00B5F7\", width=2),\n",
    "            name=\"Training Loss\",\n",
    "            legendgroup=\"train\",\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=list(range(len(val_loss))),\n",
    "            y=val_loss,\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"#FF6B6B\", width=2),\n",
    "            name=\"Validation Loss\",\n",
    "            legendgroup=\"val\",\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "    # Mark the best loss epoch\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[best_loss_epoch],\n",
    "            y=[min(val_loss)],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(color=\"#4ECDC4\", size=10, symbol=\"star\"),\n",
    "            name=f\"Best Loss Epoch ({best_loss_epoch})\",\n",
    "            legendgroup=\"best_points\",\n",
    "            hoverinfo=\"text\",\n",
    "            hovertext=f\"Best Validation Loss: {min(val_loss):.4f} at epoch {best_loss_epoch}\",\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "    # Add accuracy traces\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=list(range(len(acc))),\n",
    "            y=acc,\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"#00B5F7\", width=2),\n",
    "            name=\"Training Accuracy\",\n",
    "            legendgroup=\"train\",\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        row=1,\n",
    "        col=2,\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=list(range(len(val_acc))),\n",
    "            y=val_acc,\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"#FF6B6B\", width=2),\n",
    "            name=\"Validation Accuracy\",\n",
    "            legendgroup=\"val\",\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        row=1,\n",
    "        col=2,\n",
    "    )\n",
    "\n",
    "    # Mark the best accuracy epoch\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[best_acc_epoch],\n",
    "            y=[max(val_acc)],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(color=\"#4ECDC4\", size=10, symbol=\"star\"),\n",
    "            name=f\"Best Accuracy Epoch ({best_acc_epoch})\",\n",
    "            legendgroup=\"best_points\",\n",
    "            hoverinfo=\"text\",\n",
    "            hovertext=f\"Best Validation Accuracy: {max(val_acc):.4f} at epoch {best_acc_epoch}\",\n",
    "        ),\n",
    "        row=1,\n",
    "        col=2,\n",
    "    )\n",
    "\n",
    "    # Update layout for better appearance\n",
    "    fig.update_layout(\n",
    "        template=\"plotly_dark\",\n",
    "        paper_bgcolor=\"rgba(0,0,0,1)\",\n",
    "        plot_bgcolor=\"rgba(0,0,0,1)\",\n",
    "        title=dict(text=\"Model's Training Performance\", y=0.98),\n",
    "        height=500,\n",
    "        width=1200,\n",
    "        showlegend=True,\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.05, xanchor=\"right\", x=1),\n",
    "        xaxis_title=\"Epoch\",\n",
    "        xaxis2_title=\"Epoch\",\n",
    "        yaxis_title=\"Loss\",\n",
    "        yaxis2_title=\"Accuracy\",\n",
    "    )\n",
    "\n",
    "    # Add grid lines with dark theme colors\n",
    "    fig.update_xaxes(\n",
    "        showgrid=True,\n",
    "        gridwidth=1,\n",
    "        gridcolor=\"rgba(255,255,255,0.2)\",\n",
    "        showline=True,\n",
    "        mirror=True,\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        showgrid=True,\n",
    "        gridwidth=1,\n",
    "        gridcolor=\"rgba(255,255,255,0.2)\",\n",
    "        showline=True,\n",
    "        mirror=True,\n",
    "    )\n",
    "\n",
    "    # Show the figure\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# Plot the training history\n",
    "plot_history(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "*Now that we have a trained model, we need to evaluate its performance on the test dataset (data the model hasn't seen during training). This will give us an unbiased estimate of how well the model will perform on new, unseen data.*\n",
    "\n",
    "### Test Set Performance\n",
    "\n",
    "*First, let's calculate the overall accuracy on our test set:*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "score = seq_model.evaluate(test_ds, verbose=0)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Test Set Evaluation Results:\")\n",
    "print(f\"  Loss:     {score[0]:.4f}\")\n",
    "print(f\"  Accuracy: {score[1] * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The test accuracy gives us a good overall measure of the model's performance, but we need more detailed metrics to fully understand its strengths and weaknesses for each disease class.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Predictions on Test Images\n",
    "\n",
    "*Let's examine how our model performs on specific test images. This visual analysis helps us understand what kinds of images the model handles well and where it might struggle.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, dataset, class_names, num_images=16):\n",
    "    \"\"\"Visualize model predictions on sample images from the dataset\"\"\"\n",
    "    for image_batch, label_batch in dataset.take(1):\n",
    "        fig = plt.figure(figsize=(16, 16))\n",
    "        plt.style.use(\"dark_background\")\n",
    "        fig.suptitle(\"Model Predictions on Test Images\", fontsize=24, y=0.98)\n",
    "\n",
    "        for i in range(min(num_images, len(image_batch))):\n",
    "            plt.subplot(4, 4, i + 1)\n",
    "\n",
    "            image = image_batch[i].numpy().astype(np.uint8)\n",
    "            plt.imshow(image)\n",
    "\n",
    "            # Get model prediction for this image\n",
    "            pred = model.predict(image.reshape(1, IMAGE_SIZE, IMAGE_SIZE, 3), verbose=0)\n",
    "\n",
    "            # Extract prediction details\n",
    "            pred_label = class_names[np.argmax(pred)]\n",
    "            true_label = class_names[label_batch[i]]\n",
    "            confidence = np.max(pred) * 100\n",
    "\n",
    "            pred_label_clean = pred_label.replace(\"Potato___\", \"\").replace(\"_\", \" \")\n",
    "            true_label_clean = true_label.replace(\"Potato___\", \"\").replace(\"_\", \" \")\n",
    "\n",
    "            # Color code the title based on correctness of prediction\n",
    "            title_color = \"green\" if pred_label == true_label else \"red\"\n",
    "\n",
    "            # Set title with prediction information\n",
    "            plt.title(\n",
    "                f\"Pred: {pred_label_clean}\\nTrue: {true_label_clean}\\nConf: {confidence:.1f}%\",\n",
    "                color=title_color,\n",
    "                fontsize=10,\n",
    "                pad=8,\n",
    "            )\n",
    "\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.94)\n",
    "        plt.show()\n",
    "        break  # Process one batch\n",
    "\n",
    "\n",
    "visualize_predictions(seq_model, test_ds, class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*From these visualizations, we can observe:*\n",
    "\n",
    "1. *Green titles indicate correct predictions, red titles indicate misclassifications*\n",
    "2. *The confidence level (percentage) indicates how certain the model is about its prediction*\n",
    "3. *We can analyze which types of images are more challenging for the model*\n",
    "\n",
    "*This helps us understand the model's strengths and limitations in a practical context.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix and Classification Report\n",
    "\n",
    "*A confusion matrix is a table that summarizes the prediction results, showing the counts of true positives, false positives, true negatives, and false negatives for each class. This helps us understand which classes the model might be confusing with each other.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect true labels and predictions across the entire test set\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "\n",
    "print(\"Generating predictions on the test dataset...\")\n",
    "for i, (image_batch, label_batch) in enumerate(test_ds):\n",
    "    # Add true labels to our list\n",
    "    y_true.extend(label_batch.numpy())\n",
    "\n",
    "    # Get predictions for this batch\n",
    "    batch_predictions = seq_model.predict(image_batch, verbose=0)\n",
    "\n",
    "    # Convert prediction probabilities to class indices\n",
    "    batch_pred_classes = [np.argmax(pred) for pred in batch_predictions]\n",
    "    y_pred.extend(batch_pred_classes)\n",
    "\n",
    "    # Show progress\n",
    "    print(f\"Processed batch {i + 1}/{len(test_ds)}\", end=\"\\r\")\n",
    "\n",
    "print(f\"\\nCompleted predictions on {len(y_true)} test images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    \"\"\"Create a visually enhanced confusion matrix\"\"\"\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Convert to a DataFrame for better visualization\n",
    "    cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "\n",
    "    readable_class_names = [\n",
    "        name.replace(\"Potato___\", \"\").replace(\"_\", \" \") for name in class_names\n",
    "    ]\n",
    "    cm_df.index = readable_class_names\n",
    "    cm_df.columns = readable_class_names\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.style.use(\"dark_background\")\n",
    "\n",
    "    # Create an enhanced heatmap with both counts and percentages\n",
    "    sns.heatmap(\n",
    "        cm_df,\n",
    "        annot=True,  # Show values in cells\n",
    "        fmt=\"d\",  # Use the integer format for counts\n",
    "        cmap=\"Blues\",  # Use a color palette that's easier to interpret\n",
    "        linewidths=1,  # Add lines between cells\n",
    "        cbar=True,  # Show color bar\n",
    "        square=True,  # Make cells square-shaped\n",
    "    )\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.title(\"Confusion Matrix: Potato Disease Classification\", fontsize=16, pad=20)\n",
    "    plt.ylabel(\"Predicted Class\", fontsize=14, labelpad=10)\n",
    "    plt.xlabel(\"True Class\", fontsize=14, labelpad=10)\n",
    "\n",
    "    plt.xticks(rotation=45, ha=\"right\", fontsize=12)\n",
    "    plt.yticks(rotation=0, fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return cm_df\n",
    "\n",
    "\n",
    "cm_df = plot_confusion_matrix(y_true, y_pred, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a detailed classification report\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(\"----------------------------------\")\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    target_names=[\n",
    "        name.replace(\"Potato___\", \"\").replace(\"_\", \" \") for name in class_names\n",
    "    ],\n",
    "    digits=4,\n",
    ")\n",
    "\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The confusion matrix and classification report provide important insights:*\n",
    "\n",
    "- *Precision: The proportion of positive identifications that were actually correct*\n",
    "- *Recall: The proportion of actual positives that were correctly identified*\n",
    "- *F1-score: The harmonic mean of precision and recall*\n",
    "- *Support: The number of samples in each class*\n",
    "\n",
    "*These metrics help us understand how well our model performs for each disease class and identify any systematic misclassifications.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve Analysis\n",
    "\n",
    "*The Receiver Operating Characteristic (ROC) curve is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. For multi-class problems like ours, we plot ROC curves for each class.*\n",
    "\n",
    "*This analysis helps us understand how well the model can distinguish between classes across different threshold settings.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect prediction probabilities and true labels from the test dataset\n",
    "print(\"Generating prediction probabilities for ROC curve analysis...\")\n",
    "y_probs = []\n",
    "y_true = []\n",
    "\n",
    "\n",
    "for i, (image_batch, label_batch) in enumerate(test_ds):\n",
    "    batch_probs = seq_model.predict(image_batch, verbose=0)\n",
    "    y_probs.extend(batch_probs)\n",
    "    y_true.extend(label_batch.numpy())\n",
    "    print(f\"Processed batch {i + 1}/{len(test_ds)}\", end=\"\\r\")\n",
    "\n",
    "print(f\"\\nCollected predictions for {len(y_true)} test images\")\n",
    "\n",
    "\n",
    "y_probs = np.array(y_probs)\n",
    "y_true = np.array(y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for ROC curve calculation\n",
    "\n",
    "# Binarize the labels for multi-class ROC analysis\n",
    "# This converts integer class labels to a binary matrix representation\n",
    "y_true_bin = label_binarize(y_true, classes=np.unique(y_true))\n",
    "n_classes = y_true_bin.shape[1]\n",
    "\n",
    "# Verify data integrity\n",
    "if len(y_true) == 0 or len(y_probs) == 0 or len(y_true) != len(y_probs):\n",
    "    raise ValueError(\n",
    "        \"Empty or mismatched data: y_true and y_probs must be non-empty and have the same length.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curves and AUC for each class\n",
    "fpr, tpr, roc_auc = {}, {}, {}\n",
    "\n",
    "# Process each class separately\n",
    "for i in range(n_classes):\n",
    "    # Calculate false positive rate and true positive rate\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_probs[:, i])\n",
    "    # Calculate the area under the curve\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Calculate the micro-average ROC curve and AUC (treats the problem as binary by flattening all classes)\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_bin.ravel(), y_probs.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Calculate macro-average ROC curve and AUC (average of per-class curves)\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "mean_tpr /= n_classes\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"dark_background\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplots_adjust(top=0.9, bottom=0.18)\n",
    "\n",
    "# Define class-specific colors and readable class names\n",
    "colors = [\"#00B5F7\", \"#FF6B6B\", \"#4ECDC4\", \"#FFD93D\", \"#FF8066\", \"#95A5A6\"]\n",
    "readable_class_names = [\n",
    "    name.replace(\"Potato___\", \"\").replace(\"_\", \" \") for name in class_names\n",
    "]\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "for i in range(n_classes):\n",
    "    plt.plot(\n",
    "        fpr[i],\n",
    "        tpr[i],\n",
    "        color=colors[i % len(colors)],\n",
    "        lw=2.5,\n",
    "        label=f\"{readable_class_names[i]} (AUC = {roc_auc[i]:.3f})\",\n",
    "    )\n",
    "\n",
    "# Plot micro-average ROC curve\n",
    "plt.plot(\n",
    "    fpr[\"micro\"],\n",
    "    tpr[\"micro\"],\n",
    "    label=f\"Micro-average (AUC = {roc_auc['micro']:.3f})\",\n",
    "    color=\"#FF69B4\",\n",
    "    linestyle=\":\",\n",
    "    lw=2,\n",
    ")\n",
    "\n",
    "# Plot macro-average ROC curve\n",
    "plt.plot(\n",
    "    fpr[\"macro\"],\n",
    "    tpr[\"macro\"],\n",
    "    label=f\"Macro-average (AUC = {roc_auc['macro']:.3f})\",\n",
    "    color=\"#87CEEB\",\n",
    "    linestyle=\":\",\n",
    "    lw=2,\n",
    ")\n",
    "\n",
    "# Plot diagonal line representing random chance\n",
    "plt.plot([0, 1], [0, 1], \"w--\", lw=2, label=\"Random Chance (AUC = 0.5)\")\n",
    "\n",
    "# Customize the plot appearance\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=14)\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=14)\n",
    "plt.title(\"ROC Curves for Potato Disease Classification\", fontsize=16, pad=20)\n",
    "plt.legend(loc=\"lower right\", fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add explanatory text with light background\n",
    "plt.figtext(\n",
    "    0.5,\n",
    "    0.01,\n",
    "    \"A perfect classifier would have an AUC of 1.0 (top-left corner)\\n\"\n",
    "    \"Random guessing would give an AUC of 0.5 (diagonal line)\",\n",
    "    ha=\"center\",\n",
    "    fontsize=10,\n",
    "    color=\"white\",\n",
    "    bbox={\"facecolor\": \"#2C3E50\", \"alpha\": 0.7, \"pad\": 5},\n",
    ")\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the ROC Curves\n",
    "\n",
    "*From the ROC curves, we can observe:*\n",
    "\n",
    "- **Area Under the Curve (AUC)**: A higher AUC indicates better model performance\n",
    "  - AUC = 1.0: Perfect classification\n",
    "  - AUC = 0.5: No better than random guessing (the diagonal line)\n",
    "\n",
    "- **Micro-average**: Calculates metrics globally by considering each element of the label indicator matrix\n",
    "\n",
    "- **Macro-average**: Calculates metrics for each class and takes the average (treats all classes equally)\n",
    "\n",
    "*The high AUC values across all classes indicate that our model has strong discriminative power for potato disease classification.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Saving and Deployment\n",
    "\n",
    "*After training and evaluating our model, we need to save it so it can be loaded and used for future predictions without retraining.*\n",
    "\n",
    "### Saving the Trained Model\n",
    "\n",
    "*We'll save our model in the TensorFlow Keras format (.keras), which preserves both the model architecture and trained weights.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define save directory\n",
    "save_dir = \"SAVED_MODELS\"\n",
    "\n",
    "# Create a directory if it doesn't exist\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Function to get the next available model number\n",
    "def get_next_model_number():\n",
    "    existing_models = [\n",
    "        f\n",
    "        for f in os.listdir(save_dir)\n",
    "        if f.startswith(\"model_\") and f.endswith(\".keras\")\n",
    "    ]\n",
    "    if not existing_models:\n",
    "        return 0\n",
    "    existing_numbers = [\n",
    "        int(f.replace(\"model_\", \"\").replace(\".keras\", \"\")) for f in existing_models\n",
    "    ]\n",
    "    return max(existing_numbers) + 1\n",
    "\n",
    "\n",
    "# Get the next available model number\n",
    "model_version = get_next_model_number()\n",
    "\n",
    "# Define the complete save path\n",
    "model_path = os.path.join(save_dir, f\"model_{model_version}.keras\")\n",
    "\n",
    "# Save the model\n",
    "print(f\"Saving model to {model_path}...\")\n",
    "seq_model.save(model_path)\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the model can be loaded again\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Try loading the model to verify it saved correctly\n",
    "print(f\"Verifying model by loading it from {model_path}...\")\n",
    "try:\n",
    "    loaded_model = load_model(model_path)\n",
    "    print(\"Model loaded successfully! Architecture:\")\n",
    "    loaded_model.summary()\n",
    "    print(\"\\nModel verification complete. The model is ready for deployment.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Deployment Considerations\n",
    "\n",
    "*Now that we have a trained and saved model, it can be deployed in various ways:*\n",
    "\n",
    "1. **Web Application**: Using frameworks like Flask, Django, or Gradio to create a user-friendly interface\n",
    "2. **Mobile Application**: Converting the model to TensorFlow Lite for mobile deployment\n",
    "3. **Cloud API**: Hosting the model on cloud platforms like AWS, Azure, or Google Cloud\n",
    "4. **Edge Devices**: Deploying to IoT devices for in-field detection\n",
    "\n",
    "*The deployment approach depends on the specific use case and target users. Here we used Gradio for the Deployment*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "MODEL_PATH = \"/content/model_0.keras\"  # Update this path to your saved model\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "# Define class names (should match your training data)\n",
    "CLASS_NAMES = [\"Potato___Early_blight\", \"Potato___Late_blight\", \"Potato___healthy\"]\n",
    "\n",
    "# Image preprocessing parameters\n",
    "IMAGE_SIZE = 256\n",
    "\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    Preprocess the input image for model prediction\n",
    "    \"\"\"\n",
    "    # Convert the PIL image to a numpy array\n",
    "    if isinstance(image, Image.Image):\n",
    "        image = np.array(image)\n",
    "\n",
    "    # Add batch dimension\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def create_probability_plot(probabilities, class_names):\n",
    "    \"\"\"\n",
    "    Create a bar plot of prediction probabilities\n",
    "    \"\"\"\n",
    "    # Set the dark theme\n",
    "    plt.style.use(\"dark_background\")\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    fig.subplots_adjust(top=0.9, bottom=0.2)\n",
    "    fig.patch.set_facecolor(\"#1e1e1e\")\n",
    "    ax.set_facecolor(\"#1e1e1e\")\n",
    "\n",
    "    # Create a color map - highlight the highest probability with modern colors\n",
    "    colors = [\n",
    "        \"#ff6b6b\" if i != np.argmax(probabilities) else \"#4ecdc4\"\n",
    "        for i in range(len(probabilities))\n",
    "    ]\n",
    "\n",
    "    bars = ax.bar(\n",
    "        class_names,\n",
    "        probabilities * 100,\n",
    "        color=colors,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.5,\n",
    "        alpha=0.9,\n",
    "    )\n",
    "\n",
    "    # Add percentage labels on bars with white text\n",
    "    for bar, prob in zip(bars, probabilities):\n",
    "        height = bar.get_height()\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2.0,\n",
    "            height + 1,\n",
    "            f\"{prob * 100:.1f}%\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontweight=\"bold\",\n",
    "            color=\"white\",\n",
    "            fontsize=11,\n",
    "        )\n",
    "\n",
    "    # Style the plot with white text\n",
    "    ax.set_title(\n",
    "        \"Potato Disease Classification Probabilities\",\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "        color=\"white\",\n",
    "        pad=20,\n",
    "    )\n",
    "    ax.set_xlabel(\"Disease Classes\", fontsize=14, color=\"white\")\n",
    "    ax.set_ylabel(\"Probability (%)\", fontsize=14, color=\"white\")\n",
    "    ax.set_ylim(0, 105)\n",
    "\n",
    "    # Style tick labels\n",
    "    ax.tick_params(axis=\"x\", colors=\"white\", labelsize=12)\n",
    "    ax.tick_params(axis=\"y\", colors=\"white\", labelsize=12)\n",
    "\n",
    "    # Add a subtle grid for better readability\n",
    "    ax.grid(axis=\"y\", alpha=0.3, color=\"gray\", linestyle=\"--\")\n",
    "\n",
    "    # Remove top and right spines for a cleaner look\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_color(\"white\")\n",
    "    ax.spines[\"bottom\"].set_color(\"white\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Convert plot to image\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(\n",
    "        buf,\n",
    "        format=\"png\",\n",
    "        dpi=150,\n",
    "        bbox_inches=\"tight\",\n",
    "        facecolor=\"#1e1e1e\",\n",
    "        edgecolor=\"none\",\n",
    "    )\n",
    "    buf.seek(0)\n",
    "    plt.close()\n",
    "\n",
    "    # Reset to the default style to avoid affecting other plots\n",
    "    plt.style.use(\"default\")\n",
    "\n",
    "    return Image.open(buf)\n",
    "\n",
    "\n",
    "def get_disease_info(predicted_class):\n",
    "    \"\"\"\n",
    "    Return information about the predicted disease\n",
    "    \"\"\"\n",
    "    disease_info = {\n",
    "        \"Potato___Early_blight\": {\n",
    "            \"description\": \"Early blight is a common potato disease caused by Alternaria solani. It appears as dark spots with concentric rings on leaves.\",\n",
    "            \"treatment\": \"Use fungicides, practice crop rotation, and ensure proper plant spacing for air circulation.\",\n",
    "            \"severity\": \"Moderate\",\n",
    "        },\n",
    "        \"Potato___Late_blight\": {\n",
    "            \"description\": \"Late blight is a serious potato disease caused by Phytophthora infestans. It can cause rapid destruction of leaves and tubers.\",\n",
    "            \"treatment\": \"Apply fungicides preventively, remove infected plants, and avoid overhead watering.\",\n",
    "            \"severity\": \"High\",\n",
    "        },\n",
    "        \"Potato___healthy\": {\n",
    "            \"description\": \"The potato plant appears healthy with no visible signs of disease.\",\n",
    "            \"treatment\": \"Continue regular monitoring and maintain good agricultural practices.\",\n",
    "            \"severity\": \"None\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return disease_info.get(\n",
    "        predicted_class,\n",
    "        {\n",
    "            \"description\": \"Unknown disease classification.\",\n",
    "            \"treatment\": \"Consult with agricultural experts.\",\n",
    "            \"severity\": \"Unknown\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "def predict_disease(image):\n",
    "    \"\"\"\n",
    "    Main prediction function for Gradio interface\n",
    "    \"\"\"\n",
    "    if image is None:\n",
    "        return \"Please upload an image\", None, \"\"\n",
    "\n",
    "    try:\n",
    "        # Preprocess the image\n",
    "        processed_image = preprocess_image(image)\n",
    "\n",
    "        # Make prediction\n",
    "        predictions = model.predict(processed_image, verbose=0)\n",
    "        probabilities = predictions[0]\n",
    "\n",
    "        # Get predicted class\n",
    "        predicted_class_idx = np.argmax(probabilities)\n",
    "        predicted_class = CLASS_NAMES[predicted_class_idx]\n",
    "        confidence = probabilities[predicted_class_idx] * 100\n",
    "\n",
    "        # Create probability plot\n",
    "        disease_names = [\n",
    "            name.replace(\"Potato__\", \"\").replace(\"_\", \" \").title()\n",
    "            for name in CLASS_NAMES\n",
    "        ]\n",
    "        plot_image = create_probability_plot(probabilities, disease_names)\n",
    "\n",
    "        # Get disease information\n",
    "        disease_info = get_disease_info(predicted_class)\n",
    "\n",
    "        # Format results\n",
    "        result_text = f\"\"\"\n",
    "                    ## 🔍 **Prediction Results**\n",
    "\n",
    "                    **Predicted Disease:** {predicted_class.replace(\"Potato___\", \"\").replace(\"_\", \" \").title()}\n",
    "                    **Confidence:** {confidence:.2f}%\n",
    "\n",
    "                    ## 📋 **Disease Information**\n",
    "\n",
    "                    **Description:** {disease_info[\"description\"]}\n",
    "\n",
    "                    **Recommended Treatment:** {disease_info[\"treatment\"]}\n",
    "\n",
    "                    **Severity Level:** {disease_info[\"severity\"]}\n",
    "\n",
    "                    ---\n",
    "                    *Note: This is an AI-based prediction. For critical decisions, please consult with agricultural experts.*\n",
    "                    \"\"\"\n",
    "\n",
    "        return (\n",
    "            result_text,\n",
    "            plot_image,\n",
    "            f\"Prediction: {predicted_class.replace('Potato___', '').replace('_', ' ').title()} ({confidence:.1f}%)\",\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error processing image: {str(e)}\", None, \"Error occurred\"\n",
    "\n",
    "\n",
    "# Create Gradio interface\n",
    "def create_gradio_app():\n",
    "    \"\"\"\n",
    "    Create and configure the Gradio interface\n",
    "    \"\"\"\n",
    "\n",
    "    # Custom CSS for better styling\n",
    "    css = \"\"\"\n",
    "    .gradio-container {\n",
    "        font-family: 'Arial', sans-serif;\n",
    "    }\n",
    "    .output-markdown {\n",
    "        font-size: 14px;\n",
    "    }\n",
    "    .image-upload {\n",
    "        border: 2px dashed #4CAF50;\n",
    "        border-radius: 10px;\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    with gr.Blocks(css=css, title=\"Potato Disease Classifier\") as app:\n",
    "        gr.Markdown(\"\"\"\n",
    "        # 🥔 Potato Disease Classification System\n",
    "\n",
    "        Upload an image of a potato leaf to detect potential diseases. The system can identify:\n",
    "        - **Early Blight** - Caused by Alternaria solani\n",
    "        - **Late Blight** - Caused by Phytophthora infestans\n",
    "        - **Healthy** - No disease detected\n",
    "\n",
    "        ---\n",
    "        \"\"\")\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                # Input section\n",
    "                gr.Markdown(\"### 📤 Upload Image\")\n",
    "                input_image = gr.Image(\n",
    "                    type=\"pil\",\n",
    "                    label=\"Upload a potato leaf image\",\n",
    "                    elem_classes=[\"image-upload\"],\n",
    "                )\n",
    "\n",
    "                predict_btn = gr.Button(\n",
    "                    \"🔍 Analyze Disease\", variant=\"primary\", size=\"lg\"\n",
    "                )\n",
    "\n",
    "                # Quick status\n",
    "                status_text = gr.Textbox(label=\"Status\", interactive=False, max_lines=1)\n",
    "\n",
    "            with gr.Column(scale=2):\n",
    "                # Output section\n",
    "                gr.Markdown(\"### 📊 Results\")\n",
    "\n",
    "                with gr.Row():\n",
    "                    result_text = gr.Markdown(\n",
    "                        value=\"Upload an image and click 'Analyze Disease' to see results.\",\n",
    "                        elem_classes=[\"output-markdown\"],\n",
    "                    )\n",
    "\n",
    "                probability_plot = gr.Image(\n",
    "                    label=\"Probability Distribution\", type=\"pil\"\n",
    "                )\n",
    "\n",
    "        # Examples section\n",
    "        gr.Markdown(\"### 🖼️ Example Images\")\n",
    "        gr.Markdown(\"*Click on any example image below to test the classifier:*\")\n",
    "\n",
    "        # You can add example images here if you have them\n",
    "        gr.Examples(\n",
    "            examples=[\n",
    "                [\"/content/Early_Blight.JPG\"],\n",
    "                [\"/content/Late_Blight.JPG\"],\n",
    "                [\"/content/Healthy.JPG\"],\n",
    "            ],\n",
    "            inputs=input_image,\n",
    "        )\n",
    "\n",
    "        # Connect the prediction function\n",
    "        predict_btn.click(\n",
    "            fn=predict_disease,\n",
    "            inputs=[input_image],\n",
    "            outputs=[result_text, probability_plot, status_text],\n",
    "        )\n",
    "\n",
    "        # Also allow prediction on image upload\n",
    "        input_image.change(\n",
    "            fn=predict_disease,\n",
    "            inputs=[input_image],\n",
    "            outputs=[result_text, probability_plot, status_text],\n",
    "        )\n",
    "\n",
    "        gr.Markdown(\"\"\"\n",
    "        ---\n",
    "        ### ℹ️ **Important Notes:**\n",
    "        - Ensure the image clearly shows potato leaves\n",
    "        - Good lighting and focus improve accuracy\n",
    "        - This tool is for educational/research purposes\n",
    "        - Always verify results with agricultural experts for critical decisions\n",
    "\n",
    "        **Model Accuracy:** ~98.5% on test dataset\n",
    "        \"\"\")\n",
    "\n",
    "    return app\n",
    "\n",
    "\n",
    "# Launch the app\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Create and launch the Gradio app\n",
    "        app = create_gradio_app()\n",
    "\n",
    "        # Launch with custom settings\n",
    "        app.launch(\n",
    "            share=True,  # Set to True to create a public link\n",
    "            server_name=\"0.0.0.0\",  # Allow access from any IP\n",
    "            server_port=7860,  # Default Gradio port\n",
    "            debug=True,  # Enable debug mode\n",
    "            show_error=True,  # Show detailed error messages\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error launching Gradio app: {e}\")\n",
    "        print(\"Make sure you have installed all required packages:s\")\n",
    "        print(\"pip install gradio tensorflow pillow matplotlib seaborn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Future Work\n",
    "\n",
    "*This project successfully demonstrates how deep learning can be applied to agricultural challenges, specifically the detection of potato plant diseases. Our model achieved high accuracy in distinguishing between early blight, late blight, and healthy potato plants.*\n",
    "\n",
    "### Key Achievements\n",
    "\n",
    "1. **Effective Disease Classification**: The model achieved approximately 95% accuracy on the test dataset, demonstrating its effectiveness in identifying potato diseases.\n",
    "\n",
    "2. **User-Friendly Interface**: We created an intuitive web application that allows farmers and agricultural experts to use the model without technical knowledge.\n",
    "\n",
    "3. **Comprehensive Pipeline**: We implemented a complete machine learning pipeline from data preparation through model training to deployment.\n",
    "\n",
    "### Limitations and Future Improvements\n",
    "\n",
    "1. **Dataset Expansion**: \n",
    "   - Include more disease classes (viral diseases, nutrient deficiencies, etc.)\n",
    "   - Add more images with varying lighting conditions, angles, and backgrounds\n",
    "   - Incorporate time-series data to track disease progression\n",
    "\n",
    "2. **Model Enhancements**:\n",
    "   - Experiment with more advanced architectures like ResNet, EfficientNet, or Vision Transformers\n",
    "   - Implement explainable AI techniques to highlight which parts of the leaf influenced the classification\n",
    "   - Add disease severity estimation (percentage of leaf affected)\n",
    "\n",
    "3. **Deployment Improvements**:\n",
    "   - Develop a mobile application for field use without internet connectivity\n",
    "   - Implement a recommendation system for treatment options based on disease severity\n",
    "   - Add multi-language support for global use\n",
    "\n",
    "### Potential Impact\n",
    "\n",
    "This technology has the potential to significantly impact potato farming by:\n",
    "\n",
    "- Enabling early disease detection before symptoms are visible to the human eye\n",
    "- Reducing unnecessary pesticide use through targeted treatment\n",
    "- Decreasing crop losses and improving food security\n",
    "- Making expert knowledge more accessible to small-scale farmers\n",
    "\n",
    "*With further development and refinement, this system could become an invaluable tool for sustainable agriculture and food security.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References and Resources\n",
    "\n",
    "### Datasets\n",
    "\n",
    "- PlantVillage Dataset: [Kaggle - Plant Village](https://www.kaggle.com/datasets/arjuntejaswi/plant-village)\n",
    "\n",
    "### Technical Resources\n",
    "\n",
    "- TensorFlow Documentation: [https://www.tensorflow.org/api_docs](https://www.tensorflow.org/api_docs)\n",
    "- Keras Documentation: [https://keras.io/api/](https://keras.io/api/)\n",
    "- Gradio Documentation: [https://gradio.app/docs/](https://gradio.app/docs/)\n",
    "\n",
    "### Scientific References\n",
    "\n",
    "1. Mohanty, S.P., Hughes, D.P. & Salathé, M. (2016). Using Deep Learning for Image-Based Plant Disease Detection. Frontiers in Plant Science, 7:1419.\n",
    "\n",
    "2. Ferentinos, K.P. (2018). Deep learning models for plant disease detection and diagnosis. Computers and Electronics in Agriculture, 145, 311-318.\n",
    "\n",
    "3. Singh, V., & Misra, A. K. (2017). Detection of plant leaf diseases using image segmentation and soft computing techniques. Information Processing in Agriculture, 4(1), 41-49.\n",
    "\n",
    "### Additional Learning Resources\n",
    "\n",
    "- [CNN Explainer](https://poloclub.github.io/cnn-explainer/): Interactive visualization for understanding convolutional neural networks\n",
    "- [Deep Learning for Computer Vision](https://www.coursera.org/specializations/deep-learning): Coursera specialization by Andrew Ng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
